{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "y[y==-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys, tXs = y, tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optional: normalize rows\n",
    "row_sums = tXs.max(axis=1)\n",
    "tXs = tXs / row_sums[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tXs,_,_= standardize(tXs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tXs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crazy Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines (all methods should get similar estimates of w and mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit with Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from least_squares import least_squares\n",
    "from least_squares import least_squares_GD_auto, least_squares_SGD_simple\n",
    "max_iters = 1000\n",
    "batch_size = 100\n",
    "w0 = np.zeros(tXs.shape[1])\n",
    "gamma = 0.1\n",
    "\n",
    "ls_mse, w_ls = least_squares(ys, tXs)\n",
    "gdls_mse, w_gdls = least_squares_GD_auto(ys, tXs, max_iters, w0)\n",
    "sgdls_mse, w_sgdls = least_squares_SGD_simple(ys, tXs, max_iters, batch_size, w0, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.080860029136592723,\n",
       " array([  6.19262784e-01,  -3.48254381e-03,  -2.00669630e-01,\n",
       "         -2.60510267e-01,   1.25051152e-01,  -5.16690891e+01,\n",
       "          1.14947912e+00,  -3.25619614e+00,   2.65925968e-01,\n",
       "         -1.28704959e-02,  -2.51140179e+02,  -9.88839522e-03,\n",
       "          6.02796865e-02,   6.04582638e+01,   4.90322633e+01,\n",
       "          1.44128890e-02,   1.71586339e-02,   4.80751966e+01,\n",
       "          1.42073082e-02,   1.79759768e-02,   1.10351021e-01,\n",
       "          1.28078416e-02,  -2.49591704e-02,  -1.01030590e-01,\n",
       "         -5.83804524e-02,  -8.61207727e-01,   9.59726966e-01,\n",
       "         -1.15020157e+00,  -2.96211017e+00,  -2.26912268e+00,\n",
       "          2.12680338e+02]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_mse, w_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.081090094634570301,\n",
       " array([ 0.61749087, -0.00350895, -0.20033792, -0.26202847,  0.12719733,\n",
       "        -0.09113578,  0.86489901, -0.1051342 ,  0.26675069, -0.01341465,\n",
       "         0.03105237, -0.00945033,  0.0596616 , -0.09290793,  0.38227467,\n",
       "         0.01393942,  0.01687884,  0.1784187 ,  0.01385662,  0.01756573,\n",
       "         0.11131028,  0.01250298, -0.02464514, -0.10994267,  0.01831884,\n",
       "         0.01313335,  0.01557331, -0.09929778, -0.09599082, -0.09546416,\n",
       "        -0.09091669]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdls_mse, w_gdls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.082362831309290577,\n",
       " array([ 0.60448291,  0.00934108, -0.21317646, -0.1922969 ,  0.0879337 ,\n",
       "        -0.0344858 ,  0.45262074, -0.04375892,  0.23290884, -0.02794791,\n",
       "         0.05733164, -0.02020582,  0.06437941, -0.03690732,  0.32894465,\n",
       "         0.00295182,  0.01854217,  0.15126176,  0.00730847,  0.01309575,\n",
       "         0.12503352,  0.00753471, -0.02478818, -0.1114413 ,  0.01192941,\n",
       "         0.0084104 ,  0.0087273 , -0.03550114, -0.03761911, -0.03775579,\n",
       "        -0.04158819]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdls_mse, w_sgdls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ridge_regression import ridge_regression, ridge_regression_auto\n",
    "\n",
    "lambdas = np.logspace(-4, 2, 10)\n",
    "kfold=4\n",
    "\n",
    "ridge_mse, w_ridge = ridge_regression(ys, tXs, 0.5)\n",
    "ridge_kfold_mse, w_ridge_kfold = ridge_regression_auto(ys, tXs, kfold, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.084338419697090022,\n",
       " array([  3.42667315e-01,  -2.48940677e-02,  -1.87680407e-01,\n",
       "         -2.08467263e-01,   1.99183952e-02,  -2.08148101e+00,\n",
       "          9.40649031e-01,   2.01215133e+00,   2.64751018e-01,\n",
       "         -1.49863501e-02,   3.66952090e-02,  -6.60167663e-02,\n",
       "          3.34235282e-02,   1.35291344e+00,   1.37807891e-01,\n",
       "          1.02087026e-03,  -4.53907328e-04,   1.12964732e-01,\n",
       "         -2.85992386e-04,   5.00546006e-04,   5.33922076e-02,\n",
       "         -7.50055512e-04,  -4.28039120e-02,  -1.23804869e-01,\n",
       "          6.30566927e-01,  -6.15266050e-02,  -4.09253809e-01,\n",
       "         -1.86952547e+00,   1.75633978e-01,  -3.54930287e-01,\n",
       "         -8.89847886e-02]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_mse, w_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.084699623611429339,\n",
       " array([  3.42219522e-01,  -2.64856674e-02,  -1.85776978e-01,\n",
       "         -2.13196914e-01,   2.63477858e-02,  -5.70440482e-02,\n",
       "          6.26439529e-01,  -5.52562231e-02,   2.64770305e-01,\n",
       "         -1.73391502e-02,   3.83944471e-02,  -6.45723565e-02,\n",
       "          3.39353811e-02,  -5.07791709e-02,   1.37308973e-01,\n",
       "          1.23762736e-03,  -7.48197114e-04,   1.06693577e-01,\n",
       "         -3.82245277e-04,   7.65432579e-05,   4.98488396e-02,\n",
       "         -1.08354113e-03,  -5.20968759e-02,  -1.35172210e-01,\n",
       "          1.56404616e-01,   7.98005992e-03,   6.64787596e-03,\n",
       "         -1.88468179e-01,  -5.68719683e-02,  -6.02392962e-02,\n",
       "         -8.65782472e-02]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_kfold_mse, w_ridge_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from logistic_regression import logistic_regression, reg_logistic_regression\n",
    "\n",
    "#NOTE: loss here is different (includes log terms) so it will differ from mse above\n",
    "\n",
    "gamma=0.1\n",
    "max_iters = 1000\n",
    "lambda_= 0.1\n",
    "\n",
    "#IMPORTANT: it is probably better to use ONLY the regularized version of log_regression for this\n",
    "#dataset as the Newton method depends on the hessian being non-singular (which is guaranteed by lambda_>0)\n",
    "lreg_reg_loss, w_lreg_reg = reg_logistic_regression(ys, tXs, lambda_, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122544.69129827122,\n",
       " array([ -1.07686643e+00,   1.02085284e-01,  -8.75814010e-01,\n",
       "         -1.62279888e+00,   2.42056216e-01,  -2.73753671e+00,\n",
       "          3.33691672e+00,   5.69404715e+00,   2.34785883e+00,\n",
       "         -7.06138640e-02,   3.72435984e-01,  -9.94627222e-01,\n",
       "          1.26062111e-01,   4.86798274e+00,   5.86799857e-01,\n",
       "          5.10846359e-03,  -2.40351825e-03,   1.02489366e+00,\n",
       "          1.57881455e-04,   5.27267271e-03,   1.61615537e-01,\n",
       "         -4.46485280e-03,  -2.10016127e-01,  -9.37010896e-01,\n",
       "         -8.03358868e-01,   1.66325083e+00,   3.11412860e-01,\n",
       "         -1.19691867e+01,   1.75356051e+00,   3.25515774e-01,\n",
       "         -4.82966734e-01]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_reg_loss, w_lreg_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from logistic_regression import reg_logistic_regression_auto\n",
    "\n",
    "max_iters = 1000\n",
    "lambdas = np.logspace(-5, 3, 15)\n",
    "kfold=10\n",
    "\n",
    "logreg_auto_loss, w_logreg_auto = reg_logistic_regression_auto(ys, tXs, kfold, max_iters, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12708.745116034943,\n",
       " array([-0.87598563,  0.22764919, -0.79292693, -0.62935127,  0.13063614,\n",
       "         0.04528145,  0.18473945,  0.04298838,  0.75497281, -0.10883116,\n",
       "         0.1318357 , -0.3929529 ,  0.19492078,  0.04491541,  0.53224663,\n",
       "         0.00249022, -0.00656369,  0.25894215,  0.00479075,  0.00562778,\n",
       "         0.08440271, -0.00701041, -0.2823877 , -0.35697111,  0.12071453,\n",
       "         0.11360302,  0.11350984,  0.03332159,  0.04442074,  0.04426192,\n",
       "        -0.26632662]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_auto_loss, w_logreg_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_log = w_logreg_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_ls = w_ridge_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "#Optional: normalize rows\n",
    "row_sums = tX_test.max(axis=1)\n",
    "tX_test = tX_test / row_sums[:, np.newaxis]\n",
    "\n",
    "tX_test,_,_= standardize(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 31)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH_LS = '../submission_ls.csv' # TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH_LOG = '../submission_log.csv'\n",
    "\n",
    "y_pred_ls = predict_labels(weights_ls, tX_test)\n",
    "y_pred_log = predict_labels_logistic(weights_log, tX_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.  1. ...,  1.  1. -1.]\n",
      "[-1. -1. -1. ...,  1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_ls)\n",
    "print(y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238,)\n",
      "(568238,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_ls.shape)\n",
    "print(y_pred_log.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, y_pred_ls, OUTPUT_PATH_LS)\n",
    "create_csv_submission(ids_test, y_pred_log, OUTPUT_PATH_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
