{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2- Text Classification\n",
    "\n",
    "### Classification using Word-Vectors\n",
    "\n",
    "For building a good text classifier, it is crucial to find a good feature representation of the input text. Here we will start by using the word vectors (word embeddings) of each word in the given tweet. For simplicity of a first baseline, we will construct the feature representation of the entire text by simply averaging the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-10-4705eb26b2ee>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-4705eb26b2ee>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    train_neg = pd.read_table(\"train_neg.txt\", names = {'Tweet'}, 'r')\u001b[0m\n\u001b[1;37m                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#Load original training sets\n",
    "train_neg = pd.read_table(\"train_neg.txt\", names = {'Tweet'}, 'r')\n",
    "train_pos = pd.read_table(\"train_pos.txt\", names = {'Tweet'})\n",
    "\n",
    "#Use 1 for positive sentiment, 0 for negative. Shouldn't forget to map 0 to -1 in the submission.\n",
    "y = np.concatenate((np.ones(len(train_pos)), np.zeros(len(train_neg))))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.concatenate((train_pos, train_neg)), y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Import the GloVe word embeddings\n",
    "glove = np.load(\"embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.81759674e-01,   5.19231251e-01,   2.54549441e-01, ...,\n",
       "          1.91792831e-01,   3.56942168e-01,   9.28574409e-02],\n",
       "       [ -5.26154337e-01,   7.10427748e-01,   2.98945462e-01, ...,\n",
       "          2.31704323e-01,   4.97874558e-01,   9.60398164e-02],\n",
       "       [ -5.87862712e-01,   8.23010640e-01,   3.20501774e-01, ...,\n",
       "          2.45922125e-01,   5.09756553e-01,   1.24753998e-01],\n",
       "       ..., \n",
       "       [  8.11289821e-01,   1.05897281e-01,  -1.16428044e+00, ...,\n",
       "          8.48653673e-01,   1.20359144e+00,   5.19036955e-01],\n",
       "       [ -2.31821282e+00,   5.29202334e-02,   4.51176901e-01, ...,\n",
       "         -4.95419071e-01,  -5.60939325e-01,  -4.07276411e-01],\n",
       "       [ -7.72139569e-01,   1.18280978e+00,   1.52951199e-03, ...,\n",
       "          1.79640052e-01,  -1.46539920e+00,   4.93587224e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assumption : the value for each word in the dictionnary maps to the row in the gloVe table\n",
    "with open('vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    text = [z.lower().replace('\\n','').split() for z in text]\n",
    "    return text\n",
    "\n",
    "#Build word vector for training set by using the average value of all word vectors in the tweet, then scale\n",
    "#vocab.get() will take a string, so we would better convert the train set to str first.\n",
    "def buildTweetVector(text):\n",
    "    vec = np.zeros(20).reshape((1, 20))\n",
    "    count = 0.\n",
    "    text=parse(text)\n",
    "    for word in text[0]:\n",
    "        if word in vocab.keys():\n",
    "            try:\n",
    "                vec += glove[vocab.get(word)].reshape((1, 20))\n",
    "                count += 1.\n",
    "            except KeyError:\n",
    "                continue\n",
    "        #else :\n",
    "         #   count += 1.\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs = np.concatenate([buildTweetVector(z) for z in x_train])\n",
    "train_vecs = scale(train_vecs)\n",
    "\n",
    "test_vecs = np.concatenate([buildTweetVector(z) for z in x_test])\n",
    "test_vecs = scale(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8114704 ,  0.91386584,  0.33460335, ...,  0.45619698,\n",
       "         0.85179866,  0.2883343 ],\n",
       "       [-0.33797025,  0.71699241,  1.14368106, ...,  0.15692889,\n",
       "         0.47306032,  0.60562117],\n",
       "       [-0.22338584,  1.2202286 ,  1.89466914, ...,  0.6236208 ,\n",
       "         0.73195409, -0.56194588],\n",
       "       ..., \n",
       "       [-0.90233667,  0.69083005,  0.65631705, ...,  0.39342529,\n",
       "         0.39453101,  0.13883045],\n",
       "       [ 1.08129493,  0.85437063,  0.23899664, ...,  0.23389847,\n",
       "        -0.09565342,  0.67764291],\n",
       "       [-0.53682688,  0.20073788, -0.46839319, ..., -1.46175691,\n",
       "        -1.09789763,  0.69226552]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5943290856475606"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try classification using stochastic logistic regression\n",
    "\n",
    "model = SGDClassifier(loss='log')\n",
    "model.fit(train_vecs, y_train)\n",
    "\n",
    "model.score(test_vecs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
